#code inspired from https://www.tensorflow.org/tutorials/generative/pix2pix?hl=fr

import tensorflow as tf
import os
import matplotlib.pyplot as plt
import sys
from pathlib import Path
current_directory = Path(__file__).parents[2]
sys.path.append(str( current_directory))
from src.GAN_model.generator import *
from src.GAN_model.discriminator import *
from src.GAN_model.data_augmentation import *
import datetime
import time

class GAN :
    """
    This class defines the GAN, how it is implemented and trained.
    It is composed of a Generator and a Discriminator.
    """
    def __init__(self):
        #define Generator and Discriminator
        self.generator = Generator()
        self.discriminator = Discriminator(256) 
        #define data augmenter for data augmentation
        self.data_augmenter = DataAugmentation()
                
        #define batch size and buffer_size, i.e., the number of elements that can be stored in the buffer 
         
        self.buffer_size = 800
        self.batch_size = 1
        
        self.current_path = os.getcwd()
        
        #define the Adam optimizers, with learning rate and beta_1 as in the Pix2Pix paper
        self.generator_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)
        self.discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)
        

        #directory where the checkpoints and logs are saved
        self.checkpoint_dir = os.path.join(self.current_path,'src','GAN_model','training_checkpoint')         
        self.log_dir = os.path.join(self.current_path,'src','GAN_model','logsfit')
        self.summary_writter = tf.summary.create_file_writer(self.log_dir +  datetime.datetime.now().strftime("%Y%m%d-%H%M%S"))

    
    def generate_images(self, model, test_input, target):
        """
        This function plots images generated by the Generator.
        It is used to evaluate the quality of images generated during training and 
        observe their evolution over time.

        Args:
        - model: The trained Generator model used to generate the images.
        - test_input: The input tensor for the Generator.
        - target: The target tensor for comparison.

        Returns:
        - None: The function saves a plot of the input, ground truth, and generated image to a specified directory.
        """
        #generated image
        prediction = model(test_input, training = True)

        title_file = ["one","two","tree","four","five"]

        #create a figure
        plt.figure(figsize = (80,30))
        display_list = [test_input[0], target[0], prediction[0]]
        
        
        title = ['input', 'ground truth', 'prediction']
        # for the semantic map, target and generated image
        for k in range (3):
            plt.subplot(1,3,k+1)
            plt.title(title[k])
            plt.axis('off')
            plt.imshow(display_list[k] *0.5 + 0.5)
        plt.tight_layout()
        #save figures
        plt.savefig(os.path.join(self.current_path,'src','GAN_model','fig' + str(title_file[0])))
        plt.close()
        
        

    def list_files(self,directory,extension):
        """This function allows to list the files of a folder and to sort them """
        return sorted([os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(extension)])
    
    def load_and_preprocess(self,image_path, annotation_path):
        """
        This function opens the images as tensors and normalizes them between -1 and 1.

        Args:
        - image_path: Path to the image file
        - annotation_path: Path to the annotation file

        Returns:
        - image: The loaded and normalized image tensor with values between -1 and 1.
        - annotation: The loaded and normalized annotation tensor with values between -1 and 1.
        """
        
        image = tf.io.read_file(image_path)
        image = tf.image.decode_jpeg(image, channels=3)
        image = tf.cast(image,tf.float32)
        image = (image/127.5 )-1


        annotation = tf.io.read_file(annotation_path)
        annotation = tf.image.decode_png(annotation, channels=1)
        annotation= tf.cast(annotation, tf.float32)
        annotation = (annotation /127.5 )-1
        
        return image, annotation

    
    def load_data(self):
        """
        This function defines the data pipeline.

        Returns:
        - train_dataset: A tf.data.Dataset object containing the training images and corresponding annotations.
        - val_dataset: A tf.data.Dataset object containing the validation images and corresponding annotations.
        """
        #define folders
        train_annotations_dir = (os.path.join(self.current_path,'data', 'clean_data_giraffe', 'train', 'annotations'))
        train_images_dir = os.path.join(self.current_path,'data', 'clean_data_giraffe', 'train','images')
        val_annotations_dir = os.path.join(self.current_path,'data', 'clean_data_giraffe', 'val', 'annotations')
        val_images_dir = os.path.join(self.current_path,'data', 'clean_data_giraffe', 'val', 'images')

        sorted_train_images = self.list_files(train_images_dir, '.jpg')
        sorted_train_annotations = self.list_files(train_annotations_dir, '.png')
        sorted_val_images = self.list_files(val_images_dir, '.jpg')
        sorted_val_annotations = self.list_files(val_annotations_dir, '.png')
 
       
        # Create datasets
        image_train_dataset = tf.data.Dataset.from_tensor_slices(sorted_train_images)
        annotation_train_dataset = tf.data.Dataset.from_tensor_slices(sorted_train_annotations)
        image_val_dataset = tf.data.Dataset.from_tensor_slices(sorted_val_images)
        annotation_val_dataset = tf.data.Dataset.from_tensor_slices(sorted_val_annotations)

       #match semantic map and real image
        train_dataset = tf.data.Dataset.zip((image_train_dataset, annotation_train_dataset))
        val_dataset = tf.data.Dataset.zip((image_val_dataset, annotation_val_dataset))
        
        train_dataset = train_dataset.map(lambda image_path, annotation_path: self.load_and_preprocess(image_path, annotation_path),
                                          num_parallel_calls=tf.data.AUTOTUNE)
        val_dataset = val_dataset.map(lambda image_path, annotation_path: self.load_and_preprocess(image_path, annotation_path),
                                        num_parallel_calls=tf.data.AUTOTUNE)
   
        return train_dataset, val_dataset
    


    @tf.function
    def training_step(self, input_image, target):
        """
        This function trains the model for one step by calculating the generator and discriminator losses,
        computing the associated gradients, and updating the model weights.
    
        Args:
        - input_image: The input semantic map tensor.
        - target: The target image tensor.
    
        Returns:
        - gen_total_loss: Total loss for the generator.
        - gen_gan_loss: Adversarial loss component of the generator.
        - gen_l1_loss: L1 loss component of the generator.
        - disc_loss: Loss for the discriminator.
        """
        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
            
            #call the generator and the discriminator
            gen_output = self.generator.model(input_image, training=True)

            disc_real_output = self.discriminator.model([input_image, target], training=True)
            disc_generated_output = self.discriminator.model([input_image, gen_output], training=True)

            #calculate losses
            gen_total_loss, gen_gan_loss, gen_l1_loss = self.generator.generator_loss(disc_generated_output, gen_output, target)
            disc_loss = self.discriminator.discriminator_loss(disc_real_output, disc_generated_output)
            
            
        #calculate gradients
        generator_gradients = gen_tape.gradient(gen_total_loss,
                                               self.generator.model.trainable_variables)
        discriminator_gradients = disc_tape.gradient(disc_loss,
                                                   self.discriminator.model.trainable_variables)
        #apply gradients with the optimizers
        self.generator_optimizer.apply_gradients(zip(generator_gradients,
                                              self.generator.model.trainable_variables))
        self.discriminator_optimizer.apply_gradients(zip(discriminator_gradients,
                                                  self.discriminator.model.trainable_variables))

        return gen_total_loss,gen_gan_loss,gen_l1_loss, disc_loss


    def load_model(self, path):
        """
        This function allows to load weights from a checkpoint file.
        """

        # creating a checkpoint
        checkpoint = tf.train.Checkpoint(generator=self.generator.model,
                                         discriminator=self.discriminator.model,
                                         generator_optimizer=self.generator_optimizer,
                                         discriminator_optimizer=self.discriminator_optimizer,
                                         )

        # creating a checkpoint manager 
        checkpoint_manager = tf.train.CheckpointManager(checkpoint, path, max_to_keep=3)
        #loading last checkpoint
        checkpoint.restore(tf.train.latest_checkpoint(path)) 
        print(f'Model restored from checkpoint at {checkpoint_manager.latest_checkpoint}')
        
    def save_model(self, base_path):
        """
        This function allows to save the model as it is in a checkpoint file.
        """
        # creating the path for the checkpoint
        timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
        path = os.path.join(base_path, f'checkpoint_{timestamp}')
        os.makedirs(path, exist_ok=True)

        # creating the checkpoint
        checkpoint = tf.train.Checkpoint(generator=self.generator.model,
                                         generator_optimizer=self.generator_optimizer,
                                         discriminator=self.discriminator.model,
                                         discriminator_optimizer=self.discriminator_optimizer)


        # creating a checkpoint manager and use it to save the model
        checkpoint_manager = tf.train.CheckpointManager(checkpoint, path, max_to_keep=3)
        checkpoint_manager.save()

        print(f'Model saved in {path}')

    
    def fit(self, train_dataset, val_dataset, epochs_nb):
        
        """
        This function defines the main training loop for the model.

        Args:
        - train_dataset: The training dataset.
        - val_dataset: The validation dataset.
        - epochs_nb: Number of epochs to train the model.

        """       

        #shuffle and batch training and validation sets
        epoch_train_dataset = train_dataset.shuffle(self.buffer_size).batch(self.batch_size, drop_remainder=True)
        epoch_val_dataset = val_dataset.shuffle(self.buffer_size).batch(self.batch_size, drop_remainder=True)
        
        #a few examples are defined and will be displayed regularly to evaluate the visual quality of the generated images
        example_target, example_input = next(iter(epoch_train_dataset.take(5)))
        augmented_example_target, augmented_example_input = self.data_augmenter.synchronized_data_augmentation(example_target, example_input)
        self.generate_images(self.generator.model, augmented_example_input, augmented_example_target)

        #starting a timer
        start_time = time.time()

        for epoch in range(epochs_nb):
            #for each epoch, reshuffle the dataset
            epoch_train_dataset = train_dataset.shuffle(self.buffer_size).batch(self.batch_size, drop_remainder=True)
            epoch_val_dataset = val_dataset.shuffle(self.buffer_size).batch(self.batch_size, drop_remainder=True)
     
            epoch_discriminator_loss = 0
            epoch_gan_loss = 0
            epoch_total_gan_loss = 0
            epoch_l1_loss = 0
            num_batches = 0

            
            # training loop
            for step, (target, input_image) in epoch_train_dataset.enumerate():
                num_batches+=1
                #apply data augmentation and perform a training step
                n_target, n_input_image = self.data_augmenter.synchronized_data_augmentation(target, input_image)
                generator_total_loss,gen_gan_loss,gen_l1_loss, disc_loss = self.training_step(n_input_image, n_target)
                
                #save the losses
                epoch_discriminator_loss += disc_loss
                epoch_gan_loss += gen_gan_loss
                epoch_total_gan_loss += generator_total_loss
                epoch_l1_loss += gen_l1_loss

            

            #losses init for tbe validation set
            val_epoch_discriminator_loss = 0
            val_epoch_gan_loss = 0
            val_epoch_total_gan_loss = 0
            val_epoch_l1_loss = 0
            val_num_batches = 0

            # Evaluate the model on the validation set, the same way as it was done for the training set
            for val_target, val_input_image in epoch_val_dataset:
                val_num_batches += 1
                
                _,val_generated_images = self.generator.model(val_input_image, training=False)
                val_disc_real_output = self.discriminator.model([val_input_image, val_target], training=False)
                val_disc_generated_output = self.discriminator.model([val_input_image, val_generated_images], training=False)

                val_gen_total_loss, val_gen_gan_loss, val_gen_l1_loss = self.generator.generator_loss(val_disc_generated_output, val_generated_images, val_target)
                val_disc_loss = self.discriminator.discriminator_loss(val_disc_real_output, val_disc_generated_output)

                val_epoch_discriminator_loss += val_disc_loss
                val_epoch_gan_loss += val_gen_gan_loss
                val_epoch_total_gan_loss += val_gen_total_loss
                val_epoch_l1_loss += val_gen_l1_loss

            # generate images to evaluate the visual quality of the generated images
            self.generate_images(self.generator.model, augmented_example_input, augmented_example_target)
            
            #saving losses on...
            with self.summary_writter.as_default():
                # on training set
                tf.summary.scalar('Train_generator_gan_loss', epoch_gan_loss / num_batches, step=epoch)
                tf.summary.scalar('Train_generator_l1_loss', epoch_l1_loss / num_batches, step=epoch)
                tf.summary.scalar('Train_discriminator_loss', epoch_discriminator_loss / num_batches, step=epoch)
                tf.summary.scalar('Train_generator_total_loss', epoch_total_gan_loss / num_batches, step=epoch)

                # on validation set
                tf.summary.scalar('Val_generator_gan_loss', val_epoch_gan_loss / val_num_batches, step=epoch)
                tf.summary.scalar('Val_generator_l1_loss', val_epoch_l1_loss / val_num_batches, step=epoch)
                tf.summary.scalar('Val_discriminator_loss', val_epoch_discriminator_loss / val_num_batches, step=epoch)
                tf.summary.scalar('Val_generator_total_loss', val_epoch_total_gan_loss / val_num_batches, step=epoch)

            
            if (epoch%3 == 0) or (epoch==0):
                #every 3 epochs, the metrics are calculated and saved
                psnr_val = []
                psnr_train = []
                ssim_val = []
                ssim_train = []
                
                print(f'Calculating psnr for validation set ...')

                for step, (target, input_image) in epoch_val_dataset.enumerate():
                    
                    prediction = self.generator.model(input_image, training = True)
                    psnr_val.append(tf.image.psnr(target, prediction, max_val=1.0))
                    ssim_val.append(tf.image.ssim(target, prediction, max_val=1.0))
                    
                print(f'Calculating psnr for training set ...')

                for step, (target, input_image) in epoch_train_dataset.enumerate():
                   

                    prediction = self.generator.model(input_image, training = True)
                    psnr_train.append(tf.image.psnr(target, prediction, max_val=1.0))
                    ssim_train.append(tf.image.ssim(target, prediction, max_val=1.0))


                avg_psnr_val = tf.reduce_mean(tf.concat(psnr_val, axis=0))
                avg_psnr_train = tf.reduce_mean(tf.concat(psnr_train, axis=0))
                avg_ssim_val = tf.reduce_mean(tf.concat(ssim_val, axis=0))
                avg_ssim_train = tf.reduce_mean(tf.concat(ssim_train, axis=0))

                #saving metrics on both sets
                with self.summary_writter.as_default():
                    tf.summary.scalar('psnr_train', avg_psnr_train, step=epoch)
                    tf.summary.scalar('psnr_val', avg_psnr_val, step=epoch)
                    tf.summary.scalar('ssim_train', avg_ssim_train, step=epoch)
                    tf.summary.scalar('ssim_val', avg_ssim_val, step=epoch)
                
            #saving the model weights in a checkpoint 
            print(f'Epoch {epoch + 1} completed generator training')
            if ((epoch+1) %10 ==0):
                self.save_model(self.checkpoint_dir)


        end_time = time.time()
        print(f'Total time is : {start_time-end_time}')
        


if __name__ == "__main__":
    GAN_model = GAN()
    train_dataset, val_dataset = GAN_model.load_data()
    GAN_model.fit( train_dataset, val_dataset,150 )
    
 
    
    
    